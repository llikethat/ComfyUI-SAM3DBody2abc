"""
GroundLink Physics-Based Foot Contact Solver
============================================

MIT Licensed physics-based foot contact detection using GroundLink neural network.
This is the PRIMARY foot contact solver, with TAPNet as fallback.

GroundLink predicts:
- 3D Ground Reaction Forces (GRF) per foot  
- Center of Pressure (CoP) per foot

From these physics predictions, we derive:
- Binary foot contact labels
- Foot skating correction via root adjustment

JOINT MAPPING:
==============
GroundLink was trained on SMPL-X poses with this SPECIFIC format:

Input tensor shape: [batch, frames, 23, 3]
- poses[:, :, 0, :] = Pelvis LOCAL TRANSLATION (not rotation!)
- poses[:, :, 1:23, :] = Body joint ROTATIONS (axis-angle, 22 joints)

SAM3DBody outputs:
- pred_joints_3d: 3D joint POSITIONS in camera space
- body_pose: axis-angle ROTATIONS (21 joints, excludes pelvis)
- global_orient: pelvis rotation (axis-angle)
- pred_cam_t: camera-space translation

We MAP the joints (not match) using two modes:
- Mode A: SMPL Rotations (accurate, matches training)
- Mode B: Joint Positions (fallback when rotations unavailable)

References:
- Paper: "GroundLink: A Dataset Unifying Human Body Movement and Ground Reaction Dynamics"
- SIGGRAPH Asia 2023, Han et al.
- License: MIT (commercial use permitted)
- GitHub: https://github.com/hanxingjian/GroundLink

Author: SAM3DBody2abc
Version: 1.0.0
"""

import numpy as np
import os
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from scipy.ndimage import gaussian_filter1d
from scipy.signal import medfilt
from scipy.spatial.transform import Rotation

torch = None


def _ensure_torch():
    """Lazy import torch."""
    global torch
    if torch is None:
        import torch as _torch
        torch = _torch
    return torch


# =============================================================================
# Joint Mapping Constants
# =============================================================================

GROUNDLINK_TOPOLOGY = [
    'pelvis_trans',  # 0 - LOCAL translation
    'left_hip', 'right_hip', 'spine1', 'left_knee', 'right_knee',
    'spine2', 'left_ankle', 'right_ankle', 'spine3', 'left_foot',
    'right_foot', 'neck', 'left_collar', 'right_collar', 'head',
    'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',
    'left_wrist', 'right_wrist', 'hand'
]


# =============================================================================
# Pose Conversion Utilities
# =============================================================================

def compute_pelvis_local_transform(
    pelvis_trans: np.ndarray,
    pelvis_orient: np.ndarray
) -> Tuple[np.ndarray, np.ndarray]:
    """Compute transformation to pelvis-local frame."""
    T = pelvis_trans.shape[0]
    
    pelvis_rot = Rotation.from_rotvec(pelvis_orient)
    euler = pelvis_rot.as_euler('xyz')
    z_only = np.zeros((T, 3))
    z_only[:, 2] = euler[:, 2]
    pelvis_rot_z = Rotation.from_euler('xyz', z_only)
    rot_matrices = pelvis_rot_z.as_matrix()
    
    pelvis_ground = pelvis_trans.copy()
    pelvis_ground[:, 2] = 0.0
    
    transform = np.zeros((T, 4, 4))
    transform[:, :3, :3] = rot_matrices
    transform[:, :3, 3] = pelvis_ground
    transform[:, 3, 3] = 1.0
    
    transform_inv = np.linalg.inv(transform)
    
    pelvis_homo = np.concatenate([pelvis_trans, np.ones((T, 1))], axis=1)
    local_homo = np.einsum('tij,tj->ti', transform_inv, pelvis_homo)
    local_trans = local_homo[:, :3]
    
    return local_trans, transform_inv


def convert_sam3d_to_groundlink(
    frames: List[Dict],
    use_rotations: bool = True,
    up_axis: str = 'y'
) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], str]:
    """Convert SAM3DBody output to GroundLink input format."""
    T = len(frames)
    
    if use_rotations:
        poses, root_trans = _convert_rotations(frames, up_axis)
        if poses is not None:
            return poses, root_trans, 'rotations'
    
    poses, root_trans = _convert_positions(frames, up_axis)
    if poses is not None:
        return poses, root_trans, 'positions'
    
    return None, None, 'none'


def _convert_rotations(frames: List[Dict], up_axis: str) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
    """Convert using SMPL rotation parameters."""
    T = len(frames)
    
    global_orients = []
    body_poses = []
    translations = []
    
    for frame in frames:
        smpl = frame.get('smpl_params', {})
        
        go = smpl.get('global_orient') or frame.get('pred_global_orient')
        if go is None:
            return None, None
        global_orients.append(np.array(go).flatten()[:3])
        
        bp = smpl.get('body_pose') or frame.get('pred_body_pose')
        if bp is None:
            return None, None
        bp = np.array(bp).flatten()
        if len(bp) < 63:
            bp = np.pad(bp, (0, 63 - len(bp)))
        body_poses.append(bp[:63].reshape(21, 3))
        
        tr = smpl.get('transl') or frame.get('pred_cam_t')
        if tr is None:
            tr = np.zeros(3)
        translations.append(np.array(tr).flatten()[:3])
    
    global_orients = np.stack(global_orients)
    body_poses = np.stack(body_poses)
    translations = np.stack(translations)
    
    if up_axis == 'y':
        translations = translations[:, [0, 2, 1]]
        translations[:, 2] *= -1
    
    local_trans, _ = compute_pelvis_local_transform(translations, global_orients)
    
    poses = np.zeros((T, 23, 3))
    poses[:, 0, :] = local_trans
    poses[:, 1, :] = global_orients
    poses[:, 2:23, :] = body_poses
    
    return poses, translations


def _convert_positions(frames: List[Dict], up_axis: str) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
    """Convert using joint positions (fallback mode)."""
    T = len(frames)
    
    all_joints = []
    translations = []
    
    for frame in frames:
        joints = frame.get('pred_joints_3d') or frame.get('pred_joints') or frame.get('joints_3d')
        if joints is None:
            return None, None
            
        joints = np.array(joints)
        if joints.ndim == 1:
            joints = joints.reshape(-1, 3)
        
        if len(joints) < 22:
            return None, None
        
        all_joints.append(joints[:22])
        
        tr = frame.get('pred_cam_t') or frame.get('smpl_params', {}).get('transl')
        if tr is None:
            tr = joints[0]
        translations.append(np.array(tr).flatten()[:3])
    
    all_joints = np.stack(all_joints)
    translations = np.stack(translations)
    
    if up_axis == 'y':
        all_joints = all_joints[:, :, [0, 2, 1]]
        all_joints[:, :, 2] *= -1
        translations = translations[:, [0, 2, 1]]
        translations[:, 2] *= -1
    
    pelvis_pos = all_joints[:, 0, :]
    pelvis_ground = pelvis_pos.copy()
    pelvis_ground[:, 2] = 0
    local_joints = all_joints - pelvis_ground[:, np.newaxis, :]
    
    poses = np.zeros((T, 23, 3))
    poses[:, 0, :] = local_joints[:, 0, :]
    poses[:, 1:23, :] = local_joints[:, :22, :]
    
    return poses, translations


# =============================================================================
# GroundLink Neural Network
# =============================================================================

class GroundLinkNet:
    """GroundLink neural network for GRF/CoP prediction."""
    
    def __init__(self, checkpoint_path: Optional[str] = None):
        torch = _ensure_torch()
        
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = self._build_model()
        self._checkpoint_loaded = False
        
        if checkpoint_path and os.path.exists(checkpoint_path):
            self._load_checkpoint(checkpoint_path)
        
        self.model.eval()
        self.model.to(self.device)
    
    def _build_model(self):
        """Build the DeepNetwork architecture from GroundLink."""
        torch = _ensure_torch()
        import torch.nn as nn
        
        n_joints = 23
        cnn_features = [3 * n_joints, 128, 128, 256, 256]
        features_out = 6
        cnn_kernel = 7
        fc_depth = 3
        fc_dropout = 0.2
        
        layers = []
        layers.append(nn.Flatten(start_dim=2, end_dim=-1))
        
        class TransposeLayer(nn.Module):
            def forward(self, x):
                return x.transpose(-2, -1)
        layers.append(TransposeLayer())
        
        for c_in, c_out in zip(cnn_features[:-1], cnn_features[1:]):
            layers.append(nn.Conv1d(c_in, c_out, cnn_kernel, padding=cnn_kernel//2, padding_mode='replicate'))
            layers.append(nn.ELU())
        
        layers.append(TransposeLayer())
        
        for _ in range(fc_depth - 1):
            layers.append(nn.Dropout(p=fc_dropout))
            layers.append(nn.Linear(cnn_features[-1], cnn_features[-1]))
            layers.append(nn.ELU())
        
        layers.append(nn.Dropout(p=fc_dropout))
        layers.append(nn.Linear(cnn_features[-1], 2 * features_out, bias=False))
        layers.append(nn.Unflatten(-1, (2, features_out)))
        
        return nn.Sequential(*layers)
    
    def _load_checkpoint(self, path: str):
        """Load pretrained weights."""
        torch = _ensure_torch()
        
        try:
            checkpoint = torch.load(path, map_location=self.device, weights_only=False)
            if 'model' in checkpoint:
                self.model.load_state_dict(checkpoint['model'])
            else:
                self.model.load_state_dict(checkpoint)
            self._checkpoint_loaded = True
            print(f"[GroundLink] Loaded checkpoint from {path}")
        except Exception as e:
            print(f"[GroundLink] Failed to load checkpoint: {e}")
            self._checkpoint_loaded = False
    
    @property
    def is_ready(self) -> bool:
        return self._checkpoint_loaded
    
    def predict(self, poses: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """Predict GRF and CoP from pose sequence."""
        torch = _ensure_torch()
        
        if isinstance(poses, np.ndarray):
            poses = torch.from_numpy(poses).float()
        
        if poses.dim() == 3:
            poses = poses.unsqueeze(0)
        
        poses = poses.to(self.device)
        
        with torch.no_grad():
            output = self.model(poses)
        
        output = output.squeeze(0).cpu().numpy()
        
        cop = output[..., :3]
        grf = output[..., 3:]
        
        return grf, cop
    
    def predict_contacts(
        self,
        poses: np.ndarray,
        grf_threshold: float = 0.1,
        smooth_window: int = 5
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """Predict foot contacts from poses."""
        grf, cop = self.predict(poses)
        
        grf_vertical = np.abs(grf[..., 2])
        contacts = (grf_vertical > grf_threshold).astype(np.float32)
        
        if smooth_window > 1:
            contacts[:, 0] = medfilt(contacts[:, 0], smooth_window)
            contacts[:, 1] = medfilt(contacts[:, 1], smooth_window)
        
        return contacts.astype(bool), grf, cop


# =============================================================================
# GroundLink Foot Contact Enforcer
# =============================================================================

@dataclass
class GroundLinkConfig:
    """Configuration for GroundLink solver."""
    checkpoint_path: str = ""
    grf_threshold: float = 0.1
    min_contact_frames: int = 3
    smooth_window: int = 5
    pin_feet: bool = True
    blend_frames: int = 3
    up_axis: str = 'y'
    fallback_to_heuristic: bool = True
    height_threshold: float = 0.05
    velocity_threshold: float = 0.02
    left_foot_idx: int = 10
    right_foot_idx: int = 11


class GroundLinkContactEnforcer:
    """Physics-based foot contact enforcement using GroundLink."""
    
    def __init__(self, config: Optional[GroundLinkConfig] = None):
        self.config = config or GroundLinkConfig()
        self.model = None
        self._conversion_mode = None
        self._load_model()
    
    def _load_model(self):
        """Load GroundLink model."""
        checkpoint = self.config.checkpoint_path
        
        if not checkpoint or not os.path.exists(checkpoint):
            candidates = [
                Path(__file__).parent / "groundlink_checkpoints" / "pretrained_s7_noshape.tar",
                Path(__file__).parent.parent / "models" / "groundlink" / "pretrained_s7_noshape.tar",
                Path.home() / ".cache" / "groundlink" / "pretrained_s7_noshape.tar",
            ]
            for c in candidates:
                if c.exists():
                    checkpoint = str(c)
                    break
        
        if checkpoint and os.path.exists(checkpoint):
            self.model = GroundLinkNet(checkpoint)
            if self.model.is_ready:
                print(f"[GroundLink] Model ready from {checkpoint}")
            else:
                self.model = None
    
    def process(self, mesh_sequence: Dict, verbose: bool = True) -> Dict:
        """Process mesh sequence with GroundLink physics-based contacts."""
        frames_data = mesh_sequence.get("frames", {})
        
        if isinstance(frames_data, dict):
            frame_keys = sorted(frames_data.keys())
            frames = [frames_data[k] for k in frame_keys]
        else:
            frames = frames_data
            frame_keys = None
        
        if not frames:
            return mesh_sequence
        
        poses, root_trans, mode = convert_sam3d_to_groundlink(
            frames, use_rotations=True, up_axis=self.config.up_axis
        )
        self._conversion_mode = mode
        
        if poses is None:
            if verbose:
                print("[GroundLink] Could not extract pose data")
            return mesh_sequence
        
        if verbose:
            print(f"[GroundLink] Using {mode} conversion mode")
        
        contacts = None
        grf = None
        cop = None
        method = "none"
        
        if self.model is not None and self.model.is_ready:
            try:
                contacts, grf, cop = self.model.predict_contacts(
                    poses,
                    grf_threshold=self.config.grf_threshold,
                    smooth_window=self.config.smooth_window
                )
                method = "groundlink"
                
                if verbose:
                    print(f"[GroundLink] Physics: L={contacts[:, 0].sum():.0f} R={contacts[:, 1].sum():.0f} frames")
                    
            except Exception as e:
                if verbose:
                    print(f"[GroundLink] Prediction failed: {e}")
        
        if contacts is None and self.config.fallback_to_heuristic:
            contacts = self._heuristic_contacts(frames, root_trans)
            method = "heuristic"
            
            if verbose and contacts is not None:
                print(f"[GroundLink] Heuristic: L={contacts[:, 0].sum():.0f} R={contacts[:, 1].sum():.0f} frames")
        
        if contacts is None:
            return mesh_sequence
        
        if self.config.pin_feet and root_trans is not None:
            adjusted_trans = self._enforce_contacts(frames, root_trans, contacts, verbose)
        else:
            adjusted_trans = root_trans
        
        result = mesh_sequence.copy()
        result = self._update_translations(result, frames, frame_keys, adjusted_trans)
        
        result["foot_contacts"] = {
            "method": method,
            "conversion_mode": mode,
            "contacts": contacts.tolist(),
            "grf": grf.tolist() if grf is not None else None,
            "cop": cop.tolist() if cop is not None else None,
        }
        
        return result
    
    def _heuristic_contacts(self, frames: List[Dict], root_trans: Optional[np.ndarray]) -> Optional[np.ndarray]:
        """Fallback heuristic contact detection."""
        cfg = self.config
        T = len(frames)
        
        left_foot = []
        right_foot = []
        
        for i, frame in enumerate(frames):
            joints = frame.get('pred_joints_3d') or frame.get('pred_joints')
            if joints is None:
                return None
            
            joints = np.array(joints)
            if joints.ndim == 1:
                joints = joints.reshape(-1, 3)
            
            if len(joints) <= max(cfg.left_foot_idx, cfg.right_foot_idx):
                return None
            
            trans = root_trans[i] if root_trans is not None else np.zeros(3)
            left_foot.append(joints[cfg.left_foot_idx] + trans)
            right_foot.append(joints[cfg.right_foot_idx] + trans)
        
        left_foot = np.stack(left_foot)
        right_foot = np.stack(right_foot)
        
        up_idx = 1 if cfg.up_axis == 'y' else 2
        
        left_h = left_foot[:, up_idx]
        right_h = right_foot[:, up_idx]
        ground = min(np.percentile(left_h, 5), np.percentile(right_h, 5))
        
        left_on_ground = left_h < (ground + cfg.height_threshold)
        right_on_ground = right_h < (ground + cfg.height_threshold)
        
        left_vel = np.linalg.norm(np.diff(left_foot, axis=0, prepend=left_foot[:1]), axis=1)
        right_vel = np.linalg.norm(np.diff(right_foot, axis=0, prepend=right_foot[:1]), axis=1)
        
        left_stationary = left_vel < cfg.velocity_threshold
        right_stationary = right_vel < cfg.velocity_threshold
        
        left_contact = left_on_ground & left_stationary
        right_contact = right_on_ground & right_stationary
        
        if cfg.smooth_window > 1:
            left_contact = medfilt(left_contact.astype(float), cfg.smooth_window) > 0.5
            right_contact = medfilt(right_contact.astype(float), cfg.smooth_window) > 0.5
        
        return np.stack([left_contact, right_contact], axis=1)
    
    def _enforce_contacts(self, frames: List[Dict], root_trans: np.ndarray, contacts: np.ndarray, verbose: bool) -> np.ndarray:
        """Adjust root translation to enforce foot contacts."""
        cfg = self.config
        T = len(frames)
        
        adjusted = root_trans.copy()
        
        foot_positions = [[], []]
        
        for frame in frames:
            joints = np.array(frame.get('pred_joints_3d') or frame.get('pred_joints'))
            if joints.ndim == 1:
                joints = joints.reshape(-1, 3)
            foot_positions[0].append(joints[cfg.left_foot_idx])
            foot_positions[1].append(joints[cfg.right_foot_idx])
        
        foot_positions = [np.stack(fp) for fp in foot_positions]
        
        pin_positions = [None, None]
        
        for t in range(T):
            for foot_idx in range(2):
                if contacts[t, foot_idx]:
                    foot_world = foot_positions[foot_idx][t] + adjusted[t]
                    
                    if pin_positions[foot_idx] is None:
                        pin_positions[foot_idx] = foot_world.copy()
                    else:
                        adjustment = pin_positions[foot_idx] - foot_world
                        if cfg.up_axis == 'y':
                            adjustment[1] = 0
                        else:
                            adjustment[2] = 0
                        adjusted[t] += adjustment * 0.5
                else:
                    pin_positions[foot_idx] = None
        
        adjusted = gaussian_filter1d(adjusted, sigma=1.0, axis=0)
        
        return adjusted
    
    def _update_translations(self, result: Dict, frames: List[Dict], frame_keys: Optional[List], adjusted_trans: Optional[np.ndarray]) -> Dict:
        """Update mesh sequence with adjusted translations."""
        if adjusted_trans is None:
            return result
        
        updated_frames = []
        for i, frame in enumerate(frames):
            new_frame = frame.copy()
            
            if "pred_cam_t" in new_frame:
                new_frame["pred_cam_t"] = adjusted_trans[i].tolist()
            
            if "smpl_params" in new_frame:
                new_frame["smpl_params"] = new_frame["smpl_params"].copy()
                new_frame["smpl_params"]["transl"] = adjusted_trans[i].tolist()
            
            updated_frames.append(new_frame)
        
        if frame_keys is not None:
            result["frames"] = {k: v for k, v in zip(frame_keys, updated_frames)}
        else:
            result["frames"] = updated_frames
        
        return result


# =============================================================================
# ComfyUI Nodes
# =============================================================================

class GroundLinkSolverNode:
    """
    Physics-based foot contact solver using GroundLink.
    
    PRIMARY foot contact solver. Falls back to heuristics if checkpoint unavailable.
    FULLY AUTOMATED - no manual intervention required.
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "mesh_sequence": ("MESH_SEQUENCE",),
            },
            "optional": {
                "checkpoint_path": ("STRING", {"default": "", "tooltip": "Path to GroundLink checkpoint. Leave empty for auto-detect."}),
                "grf_threshold": ("FLOAT", {"default": 0.1, "min": 0.01, "max": 0.5, "step": 0.01}),
                "smooth_window": ("INT", {"default": 5, "min": 1, "max": 15, "step": 2}),
                "pin_feet": ("BOOLEAN", {"default": True}),
                "blend_frames": ("INT", {"default": 3, "min": 1, "max": 10}),
                "up_axis": (["y", "z"], {"default": "y"}),
                "fallback_to_heuristic": ("BOOLEAN", {"default": True}),
                "log_level": (["Normal", "Verbose", "Silent"], {"default": "Normal"}),
            }
        }
    
    RETURN_TYPES = ("MESH_SEQUENCE", "STRING", "FOOT_CONTACTS")
    RETURN_NAMES = ("mesh_sequence", "status", "foot_contacts")
    FUNCTION = "solve"
    CATEGORY = "SAM3DBody2abc/Processing"
    
    def solve(self, mesh_sequence: Dict, checkpoint_path: str = "", grf_threshold: float = 0.1,
              smooth_window: int = 5, pin_feet: bool = True, blend_frames: int = 3,
              up_axis: str = "y", fallback_to_heuristic: bool = True, log_level: str = "Normal") -> Tuple[Dict, str, Dict]:
        
        verbose = log_level != "Silent"
        
        config = GroundLinkConfig(
            checkpoint_path=checkpoint_path, grf_threshold=grf_threshold,
            smooth_window=smooth_window, pin_feet=pin_feet, blend_frames=blend_frames,
            up_axis=up_axis, fallback_to_heuristic=fallback_to_heuristic,
        )
        
        enforcer = GroundLinkContactEnforcer(config)
        result = enforcer.process(mesh_sequence, verbose=verbose)
        
        foot_contacts = result.get("foot_contacts", {})
        method = foot_contacts.get("method", "none")
        mode = foot_contacts.get("conversion_mode", "unknown")
        contacts = foot_contacts.get("contacts", [])
        
        if contacts:
            arr = np.array(contacts)
            status = f"[{method}/{mode}] L={arr[:, 0].sum():.0f} R={arr[:, 1].sum():.0f} contact frames"
        else:
            status = f"[{method}] No contacts detected"
        
        return (result, status, foot_contacts)


class GroundLinkContactVisualizer:
    """Visualize GroundLink contact predictions."""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {"foot_contacts": ("FOOT_CONTACTS",)},
            "optional": {"output_format": (["timeline", "summary", "json"], {"default": "summary"})}
        }
    
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("visualization",)
    FUNCTION = "visualize"
    CATEGORY = "SAM3DBody2abc/Visualization"
    
    def visualize(self, foot_contacts: Dict, output_format: str = "summary") -> Tuple[str]:
        import json
        
        contacts = foot_contacts.get("contacts", [])
        method = foot_contacts.get("method", "unknown")
        mode = foot_contacts.get("conversion_mode", "unknown")
        
        if output_format == "json":
            return (json.dumps(foot_contacts, indent=2),)
        
        if not contacts:
            return ("No contact data",)
        
        arr = np.array(contacts)
        T = len(arr)
        
        if output_format == "summary":
            lines = [
                f"GroundLink Foot Contact Summary",
                f"=" * 40,
                f"Method: {method}",
                f"Conversion: {mode}",
                f"Total frames: {T}",
                f"Left contact: {arr[:, 0].sum():.0f} frames ({100*arr[:, 0].mean():.1f}%)",
                f"Right contact: {arr[:, 1].sum():.0f} frames ({100*arr[:, 1].mean():.1f}%)",
            ]
            return ("\n".join(lines),)
        
        else:
            lines = [f"Contact Timeline ({method}/{mode})", "-" * 50, "Frame | L | R", "-" * 50]
            for t in range(T):
                if t == 0 or (arr[t] != arr[t-1]).any() or t == T-1:
                    l = "â–ˆ" if arr[t, 0] else "Â·"
                    r = "â–ˆ" if arr[t, 1] else "Â·"
                    lines.append(f"{t:5d} | {l} | {r}")
            return ("\n".join(lines),)


# =============================================================================
# Node Registration
# =============================================================================

NODE_CLASS_MAPPINGS = {
    "GroundLinkSolver": GroundLinkSolverNode,
    "GroundLinkContactVisualizer": GroundLinkContactVisualizer,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "GroundLinkSolver": "âš¡ GroundLink Foot Contact (Physics)",
    "GroundLinkContactVisualizer": "ðŸ“Š GroundLink Contact Visualizer",
}
